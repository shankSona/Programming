# üìò PySpark Study Plan (1 Hour/Day)

## Overview
**Duration:** 8 Weeks  
**Daily Commitment:** 1 Hour  
**Goal:** From beginner to proficient in PySpark

---

## ‚úÖ Week 1: Introduction to PySpark
- [ ] Day 1: Intro to Big Data, Hadoop, Spark, PySpark
- [ ] Day 2: PySpark installation (local, Databricks, Colab)
- [ ] Day 3: Spark architecture: Driver, Executor, DAG
- [ ] Day 4: RDD vs DataFrame vs Dataset
- [ ] Day 5: SparkSession, reading CSVs
- [ ] Day 6: Basic filtering and selection
- [ ] Day 7: Practice and recap

---

## ‚úÖ Week 2: DataFrame Basics
- [ ] Day 1: Schema inference and definition
- [ ] Day 2: Column operations: `select`, `drop`, `alias`
- [ ] Day 3: Filtering rows with `filter` and `where`
- [ ] Day 4: Sorting and ordering
- [ ] Day 5: Practice on small datasets
- [ ] Day 6-7: Mini project: Explore and clean dataset

---

## ‚úÖ Week 3: Transformations & Actions
- [ ] Day 1: Transformations: `map`, `flatMap`, `distinct`
- [ ] Day 2: Actions: `collect`, `count`, `show`
- [ ] Day 3: Lazy evaluation and DAGs
- [ ] Day 4: Practice transformation chains
- [ ] Day 5: Hands-on quiz
- [ ] Day 6-7: Weekly recap + Kaggle/Spark repo problems

---

## ‚úÖ Week 4: Joins & Aggregations
- [ ] Day 1-2: Joins: inner, left, right, full, semi, anti
- [ ] Day 3: Aggregations: `groupBy`, `agg`, `count`, `sum`
- [ ] Day 4: Window functions: `row_number`, `rank`
- [ ] Day 5: Practice complex join queries
- [ ] Day 6-7: Project: Fact + Dim table joins

---

## ‚úÖ Week 5: Advanced Data Operations
- [ ] Day 1: User-Defined Functions (UDFs)
- [ ] Day 2: Handling nulls and missing values
- [ ] Day 3: Pivoting/unpivoting
- [ ] Day 4: Working with JSON and nested data
- [ ] Day 5: Dates and timestamps
- [ ] Day 6-7: Project: Clean & transform nested JSON

---

## ‚úÖ Week 6: File Formats & Partitioning
- [ ] Day 1: File formats ‚Äì Parquet, JSON, ORC
- [ ] Day 2: Partitioning vs Bucketing
- [ ] Day 3: Partition-based performance
- [ ] Day 4: Practice optimizing reads/writes
- [ ] Day 5: Read/write different formats
- [ ] Day 6-7: Project: CSV ‚Üí Transform ‚Üí Parquet

---

## ‚úÖ Week 7: PySpark SQL & Metadata
- [ ] Day 1: Temp & GlobalTemp views
- [ ] Day 2: SQL queries on DataFrames
- [ ] Day 3: Catalog operations
- [ ] Day 4: Metadata handling
- [ ] Day 5: Build metadata-driven ingestion skeleton
- [ ] Day 6-7: Project: Metadata + SQL ingestion pipeline

---

## ‚úÖ Week 8: Optimization & Real Projects
- [ ] Day 1: Catalyst optimizer, Tungsten, DAGs
- [ ] Day 2: Caching, persistence
- [ ] Day 3: Broadcast joins, skew handling
- [ ] Day 4: Monitoring with Spark UI
- [ ] Day 5: Production best practices
- [ ] Day 6-7: Capstone: End-to-end ETL pipeline

---

## üîÅ Ongoing Tasks
- [ ] Weekly blog/article reading from:
  - Databricks blog
  - Medium (search "PySpark")
  - Official Spark docs
- [ ] Practice on public datasets (e.g. Kaggle)
- [ ] Summarize weekly learnings in Obsidian

---

## üìù Notes
- Create separate notes for:
  - Functions and syntax
  - Error logs and resolutions
  - Real-life projects or ideas
- Use tags: `#pyspark`, `#bigdata`, `#etl`, `#studyplan`

